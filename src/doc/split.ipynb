{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# Stratified Splitting\n",
    "\n",
    "This notebook provides several tutorials on how to utilize any algorithm proposed\n",
    "in the **straSplit** package to split a multi-label dataset using less explored\n",
    "[stratified strategy](https://bit.ly/3s3IDA8). Please install\n",
    "[anaconda](https://www.anaconda.com/) package and other modules listed\n",
    "in [requirement.txt](../../requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# Load modules and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\MultiLabel\\\\straSplit\\\\src\\\\model'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../model')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "## load utilities\n",
    "from utils import DATASET_PATH,RESULT_PATH, data_properties\n",
    "from utils import check_type, custom_shuffle, data_properties, LabelBinarizer\n",
    "\n",
    "## load modules\n",
    "from naive2split import NaiveStratification\n",
    "from iterative2split import IterativeStratification\n",
    "from extreme2split import ExtremeStratification\n",
    "from plssvd2split import ClusterStratification\n",
    "from eigencluster2split import ClusteringEigenStratification\n",
    "from comm2split import CommunityStratification\n",
    "from enhance2split import LabelEnhancementStratification\n",
    "from active2split import ActiveStratification\n",
    "from gan2split import GANStratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_type = \"extreme\"\n",
    "split_size = 0.80\n",
    "num_epochs = 5\n",
    "num_jobs = 2\n",
    "use_solver = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname=\"birds\"\n",
    "X_name = dsname + \"_X.pkl\"\n",
    "y_name = dsname + \"_y.pkl\"\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive strategy\n",
    "\n",
    "The naive based strategy does not address the class-imbalance problem and\n",
    "neither takes into account label-correlations to split a dataset. You can\n",
    "run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to naive based stratified multi-label dataset\n",
      "   splitting:\n",
      "\t\t1. Shuffle the dataset? True\n",
      "\t\t2. Split size: 0.8\n",
      "\t\t3. Number of examples to use in each iteration: 500\n",
      "\t\t4. Number of parallel workers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Perform splitting...\n",
      "\t\t--> Splitting progress: 100.00%...\n"
     ]
    }
   ],
   "source": [
    "st = NaiveStratification(shuffle=True, split_size=split_size, batch_size=500,\n",
    "                         num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "where *training_idx* and *test_idx* are two lists corresponding the indices\n",
    "of the given data (i.e.,*y*). Let us explore the properties of the full\n",
    "dataset and the resulted splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 281\n",
      "\t>> Number of labels: 524\n",
      "\t>> Label cardinality: 1.864769\n",
      "\t>> Label density: 0.003559\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.067616\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.000883\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 70\n",
      "\t>> Number of labels: 130\n",
      "\t>> Label cardinality: 1.857143\n",
      "\t>> Label density: 0.014286\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.271429\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.016654\n"
     ]
    }
   ],
   "source": [
    "model_name = \"naive2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative strategy\n",
    "\n",
    "As mentioned in the [paper](https://bit.ly/2QqHd4V), this alrogithm perform\n",
    "iterative splitting to the dataset. These are some of the image augmentation\n",
    "techniques that avoids overfitting.\n",
    "\n",
    "CycleGAN uses a cycle consistency loss to enable training without the need\n",
    "for paired data. In other words, it can translate from one domain to another\n",
    "without a one-to-one mapping between the source and target domain.\n",
    "This opens up the possibility to do a lot of interesting tasks like photo-enhancement,\n",
    "image colorization, style transfer, etc. All you need is the source and the\n",
    "target dataset (which is simply a directory of images).\n",
    "\n",
    "As mentioned in the [paper](https://arxiv.org/abs/1703.10593), apply random\n",
    "jittering and mirroring to the training dataset. These are some of the image\n",
    "augmentation techniques that avoids overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to iteratively stratifying a multi-label\n",
      "   dataset splitting:\n",
      "\t\t1. Shuffle the dataset? True\n",
      "\t\t2. Split size: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Perform splitting (iterative)...\n",
      "\t\t--> Splitting progress: 100.00%...\r"
     ]
    }
   ],
   "source": [
    "st = IterativeStratification(shuffle=True, split_size=split_size)\n",
    "training_idx, test_idx = st.fit(y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 279\n",
      "\t>> Number of labels: 521\n",
      "\t>> Label cardinality: 1.867384\n",
      "\t>> Label density: 0.003584\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.068100\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.001513\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 72\n",
      "\t>> Number of labels: 133\n",
      "\t>> Label cardinality: 1.847222\n",
      "\t>> Label density: 0.013889\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.263889\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.024220\n"
     ]
    }
   ],
   "source": [
    "model_name = \"iterative2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme strategy\n",
    "\n",
    "CycleGAN uses a cycle consistency loss to enable training without the need for paired data. In other words, it can translate from one domain to another without a one-to-one mapping between the source and target domain.\n",
    "This opens up the possibility to do a lot of interesting tasks like photo-enhancement, image colorization, style transfer, etc. All you need is the source and the target dataset (which is simply a directory of images).\n",
    "\n",
    "As mentioned in the [paper](https://arxiv.org/abs/1703.10593), apply random jittering and mirroring to the training dataset. These are some of the image augmentation techniques that avoids overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iuGVPOo7Cce0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to stratifying a large scale multi-label\n",
      "   dataset splitting:\n",
      "\t\t1. A hyper-parameter for extreme stratification: 0.1\n",
      "\t\t2. A hyper-parameter for extreme stratification: 0.1\n",
      "\t\t3. A hyper-parameter for extreme stratification: 0.1\n",
      "\t\t4. Shuffle the dataset? True\n",
      "\t\t5. Split size: 0.8\n",
      "\t\t6. Number of loops over a dataset: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: 22\n",
      "\t\t--> Splitting progress: 100.00%; score: 2.84\n"
     ]
    }
   ],
   "source": [
    "st = ExtremeStratification(swap_probability=0.1, threshold_proportion=0.1, decay=0.1,\n",
    "                           shuffle=True, split_size=split_size, num_epochs=num_epochs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 274\n",
      "\t>> Number of labels: 513\n",
      "\t>> Label cardinality: 1.872263\n",
      "\t>> Label density: 0.003650\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.069343\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.002273\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 77\n",
      "\t>> Number of labels: 141\n",
      "\t>> Label cardinality: 1.831169\n",
      "\t>> Label density: 0.012987\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.246753\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.030994\n"
     ]
    }
   ],
   "source": [
    "model_name = \"extreme2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to stratifying a multi-label dataset splitting\n",
      "   based on clustering the covariance of X and y using PLSSVD:\n",
      "\t\t1. Number of clusters to form: 5\n",
      "\t\t2. A hyper-parameter: 0.1\n",
      "\t\t3. A hyper-parameter: 0.1\n",
      "\t\t4. A hyper-parameter: 0.1\n",
      "\t\t5. Shuffle the dataset? True\n",
      "\t\t6. Split size: 0.8\n",
      "\t\t7. Number of examples to use in each iteration: 100\n",
      "\t\t8. Number of loops over training set: 5\n",
      "\t\t9. Learning rate: 0.0001\n",
      "\t\t10. Number of parallel workers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Computing the covariance of X and y using PLSSVD: 100.00%...\n",
      "\t>> Projecting examples onto the obtained low dimensional U orthonormal basis...\n",
      "\t>> Clustering the resulted low dimensional examples...\n",
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: -10\n",
      "\t\t--> Splitting progress: 100.00%; score: -4.47\n"
     ]
    }
   ],
   "source": [
    "st = ClusterStratification(num_clusters=5, swap_probability=0.1, threshold_proportion=0.1,\n",
    "                           decay=0.1, shuffle=True, split_size=split_size, batch_size=100,\n",
    "                           num_epochs=num_epochs, lr=0.0001, num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 279\n",
      "\t>> Number of labels: 516\n",
      "\t>> Label cardinality: 1.849462\n",
      "\t>> Label density: 0.003584\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.068100\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.002416\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 72\n",
      "\t>> Number of labels: 138\n",
      "\t>> Label cardinality: 1.916667\n",
      "\t>> Label density: 0.013889\n",
      "\t>> Distinct label sets: 18\n",
      "\t>> Proportion of distinct label sets: 0.250000\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.044002\n"
     ]
    }
   ],
   "source": [
    "model_name = \"plssvd2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering eigenvalues based strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to stratifying a multi-label dataset splitting\n",
      "   based on clustering eigen values of the label adjacency matrix:\n",
      "\t\t1. Subsampling input size: 10000\n",
      "\t\t2. Number of communities: 5\n",
      "\t\t3. Constant that scales the amount of laplacian norm regularization: 2\n",
      "\t\t4. A hyper-parameter: 0.1\n",
      "\t\t5. A hyper-parameter: 0.1\n",
      "\t\t6. A hyper-parameter: 0.1\n",
      "\t\t7. Shuffle the dataset? True\n",
      "\t\t8. Split size: 0.8\n",
      "\t\t9. Number of examples to use in each iteration: 500\n",
      "\t\t10. Number of loops over training set: 5\n",
      "\t\t11. Number of parallel workers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Extracting clusters...\n",
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: 3\n",
      "\t\t--> Splitting progress: 100.00%; score: -2.47\n"
     ]
    }
   ],
   "source": [
    "st = ClusteringEigenStratification(num_subsamples=10000, num_clusters=5, sigma=2, swap_probability=0.1,\n",
    "                                   threshold_proportion=0.1, decay=0.1, shuffle=True, split_size=split_size,\n",
    "                                   batch_size=500, num_epochs=num_epochs, num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 274\n",
      "\t>> Number of labels: 509\n",
      "\t>> Label cardinality: 1.857664\n",
      "\t>> Label density: 0.003650\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.069343\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.002967\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 77\n",
      "\t>> Number of labels: 145\n",
      "\t>> Label cardinality: 1.883117\n",
      "\t>> Label density: 0.012987\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.246753\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.038943\n"
     ]
    }
   ],
   "source": [
    "model_name = \"eigencluster2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvX8sKsfMaio"
   },
   "source": [
    "## Community based splitting strategy\n",
    "\n",
    "Import the generator and the discriminator used in [Pix2Pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py) via the installed [tensorflow_examples](https://github.com/tensorflow/examples) package.\n",
    "\n",
    "The model architecture used in this tutorial is very similar to what was used in [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). Some of the differences are:\n",
    "\n",
    "* Cyclegan uses [instance normalization](https://arxiv.org/abs/1607.08022) instead of [batch normalization](https://arxiv.org/abs/1502.03167).\n",
    "* The [CycleGAN paper](https://arxiv.org/abs/1703.10593) uses a modified `resnet` based generator. This tutorial is using a modified `unet` generator for simplicity.\n",
    "\n",
    "There are 2 generators (G and F) and 2 discriminators (X and Y) being trained here. \n",
    "\n",
    "* Generator `G` learns to transform image `X` to image `Y`. $(G: X -> Y)$\n",
    "* Generator `F` learns to transform image `Y` to image `X`. $(F: Y -> X)$\n",
    "* Discriminator `D_X` learns to differentiate between image `X` and generated image `X` (`F(Y)`).\n",
    "* Discriminator `D_Y` learns to differentiate between image `Y` and generated image `Y` (`G(X)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to stratifying a multi-label dataset splitting\n",
      "   based on community detection approach:\n",
      "\t\t1. Subsampling input size: 20000\n",
      "\t\t2. Number of communities: 5\n",
      "\t\t3. Constant that scales the amount of laplacian norm regularization: 2\n",
      "\t\t4. A hyper-parameter: 0.1\n",
      "\t\t5. A hyper-parameter: 0.1\n",
      "\t\t6. A hyper-parameter: 0.1\n",
      "\t\t7. Shuffle the dataset? True\n",
      "\t\t8. Split size: 0.8\n",
      "\t\t9. Number of examples to use in each iteration: 500\n",
      "\t\t10. Number of loops over training set: 5\n",
      "\t\t11. Number of parallel workers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Building Graph...\n",
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: 17\n",
      "\t\t--> Splitting progress: 100.00%; score: 14.16\n"
     ]
    }
   ],
   "source": [
    "st = CommunityStratification(num_subsamples=20000, num_communities=5, sigma=2, swap_probability=0.1,\n",
    "                             threshold_proportion=0.1, decay=0.1, shuffle=True, split_size=split_size,\n",
    "                             batch_size=500, num_epochs=num_epochs, num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 286\n",
      "\t>> Number of labels: 533\n",
      "\t>> Label cardinality: 1.863636\n",
      "\t>> Label density: 0.003497\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.066434\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.003200\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 65\n",
      "\t>> Number of labels: 121\n",
      "\t>> Label cardinality: 1.861538\n",
      "\t>> Label density: 0.015385\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.292308\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.079500\n"
     ]
    }
   ],
   "source": [
    "model_name = \"comm2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label enhancement based strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to stratifying a multi-label dataset splitting\n",
      "   based on label enhancement approach:\n",
      "\t\t1. Subsampling input size: 10000\n",
      "\t\t2. Number of communities: 10\n",
      "\t\t3. Constant that scales the amount of laplacian norm regularization: 2\n",
      "\t\t4. A hyperparameter to balancing parameterwhich controls the fraction of the information inherited from the label propagation and the label matrix.: 0.2\n",
      "\t\t5. A hyper-parameter: 0.1\n",
      "\t\t6. A hyper-parameter: 0.1\n",
      "\t\t7. A hyper-parameter: 0.1\n",
      "\t\t8. Shuffle the dataset? True\n",
      "\t\t9. Split size: 0.8\n",
      "\t\t10. Number of examples to use in each iteration: 500\n",
      "\t\t11. Number of loops over training set: 5\n",
      "\t\t12. Number of parallel workers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Building Graph...\n",
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: 33\n",
      "\t\t--> Splitting progress: 100.00%; score: -1.66\n"
     ]
    }
   ],
   "source": [
    "st = LabelEnhancementStratification(num_subsamples=10000, num_communities=10, sigma=2, alpha=0.2,\n",
    "                                    swap_probability=0.1, threshold_proportion=0.1, decay=0.1, shuffle=True,\n",
    "                                    split_size=split_size, batch_size=500, num_epochs=num_epochs,\n",
    "                                    num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 273\n",
      "\t>> Number of labels: 501\n",
      "\t>> Label cardinality: 1.835165\n",
      "\t>> Label density: 0.003663\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.069597\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.004671\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 78\n",
      "\t>> Number of labels: 153\n",
      "\t>> Label cardinality: 1.961538\n",
      "\t>> Label density: 0.012821\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.243590\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.048639\n"
     ]
    }
   ],
   "source": [
    "model_name = \"enhance2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Active learning based splitting strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to estimating examples predictive uncertainty\n",
      "   scores to group example with high informativeness into training set\n",
      "   using a modified approach to splitting an extreme large scale multi-\n",
      "   label dataset:\n",
      "\t\t1. Subsampling labels: 10\n",
      "\t\t2. The acquisition function for estimating the predictive uncertainty: entropy\n",
      "\t\t3. Apply sklearn optimizers? False\n",
      "\t\t4. The loss function: hinge\n",
      "\t\t5. A hyper-parameter for extreme stratification: 0.1\n",
      "\t\t6. A hyper-parameter for extreme stratification: 0.1\n",
      "\t\t7. A hyper-parameter for extreme stratification: 0.1\n",
      "\t\t8. The penalty (aka regularization term): elasticnet\n",
      "\t\t9. Constant controlling the elastic term: 0.0001\n",
      "\t\t10. The elastic net mixing parameter: 0.65\n",
      "\t\t11. A cutoff threshold between two consecutive rounds: 0.05\n",
      "\t\t12. Shuffle the dataset? True\n",
      "\t\t13. Split size: 0.8\n",
      "\t\t14. Number of examples to use in each iteration: 500\n",
      "\t\t15. Number of loops over training set: 5\n",
      "\t\t16. Learning rate: 0.001\n",
      "\t\t17. How often to evaluate? 1\n",
      "\t\t18. Number of parallel workers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Training to learn a model...\n",
      "\t   1)- Epoch count (1/5)...\n",
      "  \t\t<<<------------<<<------------<<<\n",
      "  \t\t>> Feed-Backward...\n",
      "\t\t\t--> Optimizing Theta: 100.00%...\n",
      "  \t\t>>>------------>>>------------>>>\n",
      "  \t\t>> Feed-Forward...\n",
      "  \t\t>> Predictive uncertainty using entropy...\n",
      "  \t\t>> Compute cost...\n",
      "\t\t\t--> New cost: 0.7251; Old cost: inf-> Calculating cost: 94.74%...\n",
      "\t\t\t--> Epoch 1 took 0.046 seconds...\n",
      "\t   2)- Epoch count (2/5)...\n",
      "  \t\t<<<------------<<<------------<<<\n",
      "  \t\t>> Feed-Backward...\n",
      "\t\t\t--> Optimizing Theta: 100.00%...\n",
      "  \t\t>>>------------>>>------------>>>\n",
      "  \t\t>> Feed-Forward...\n",
      "  \t\t>> Predictive uncertainty using entropy...\n",
      "  \t\t>> Compute cost...\n",
      "\t\t\t--> New cost: 0.7650; Old cost: 0.7251Calculating cost: 78.95%...\n",
      "\t\t\t--> Epoch 2 took 0.058 seconds...\n",
      "\t   3)- Epoch count (3/5)...\n",
      "  \t\t<<<------------<<<------------<<<\n",
      "  \t\t>> Feed-Backward...\n",
      "\t\t\t--> Optimizing Theta: 100.00%...\n",
      "  \t\t>>>------------>>>------------>>>\n",
      "  \t\t>> Feed-Forward...\n",
      "  \t\t>> Predictive uncertainty using entropy...\n",
      "  \t\t>> Compute cost...\n",
      "\t\t\t--> New cost: 0.7954; Old cost: 0.7251Calculating cost: 89.47%...\n",
      "\t\t\t--> Epoch 3 took 0.062 seconds...\n",
      "\t   4)- Epoch count (4/5)...\n",
      "  \t\t<<<------------<<<------------<<<\n",
      "  \t\t>> Feed-Backward...\n",
      "\t\t\t--> Optimizing Theta: 100.00%...\n",
      "  \t\t>>>------------>>>------------>>>\n",
      "  \t\t>> Feed-Forward...\n",
      "  \t\t>> Predictive uncertainty using entropy...\n",
      "  \t\t>> Compute cost...\n",
      "\t\t\t--> New cost: 0.7833; Old cost: 0.7251Calculating cost: 100.00%...\n",
      "\t\t\t--> Epoch 4 took 0.057 seconds...\n",
      "\t   5)- Epoch count (5/5)...\n",
      "  \t\t<<<------------<<<------------<<<\n",
      "  \t\t>> Feed-Backward...\n",
      "\t\t\t--> Optimizing Theta: 100.00%...\n",
      "  \t\t>>>------------>>>------------>>>\n",
      "  \t\t>> Feed-Forward...\n",
      "  \t\t>> Predictive uncertainty using entropy...\n",
      "  \t\t>> Compute cost...\n",
      "\t\t\t--> New cost: 0.7892; Old cost: 0.7251Calculating cost: 94.74%...\n",
      "\t\t\t--> Epoch 5 took 0.063 seconds...\n",
      "\t  --> Training consumed 0.01 mintues\n",
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: 49.0\n",
      "\t\t--> Splitting progress: 100.00%; score: 4.05\n"
     ]
    }
   ],
   "source": [
    "st = ActiveStratification(subsample_labels_size=10, acquisition_type=\"entropy\", top_k=5, calc_ads=False,\n",
    "                          ads_percent=0.7, use_solver=use_solver, loss_function=\"hinge\", swap_probability=0.1,\n",
    "                          threshold_proportion=0.1, decay=0.1, penalty='elasticnet', alpha_elastic=0.0001,\n",
    "                          l1_ratio=0.65, alpha_l21=0.01, loss_threshold=0.05, shuffle=True,\n",
    "                          split_size=split_size, batch_size=500, num_epochs=num_epochs, lr=1e-3,\n",
    "                          display_interval=1, num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 277\n",
      "\t>> Number of labels: 505\n",
      "\t>> Label cardinality: 1.823105\n",
      "\t>> Label density: 0.003610\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.068592\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.001761\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 74\n",
      "\t>> Number of labels: 149\n",
      "\t>> Label cardinality: 2.013514\n",
      "\t>> Label density: 0.013514\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.256757\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.020645\n"
     ]
    }
   ],
   "source": [
    "model_name = \"active2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## GAN learning based splitting strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "## Configuration parameters to stratifying a multi-label dataset splitting\n",
      "   based on clustering embeddings obtained from GAN2Embed model:\n",
      "\t\t1. The dimension size of embeddings: 50\n",
      "\t\t2. The number of samples for the generator.: 20\n",
      "\t\t3. Subsampling input size: 10000\n",
      "\t\t4. Number of communities: 5\n",
      "\t\t5. Constant that scales the amount of laplacian norm regularization: 2\n",
      "\t\t6. Updating ratio when choose the trees: 2\n",
      "\t\t7. Window size to skip.: 2\n",
      "\t\t8. A hyper-parameter: 0.1\n",
      "\t\t9. A hyper-parameter: 0.1\n",
      "\t\t10. A hyper-parameter: 0.1\n",
      "\t\t11. Shuffle the dataset? True\n",
      "\t\t12. Split size: 0.8\n",
      "\t\t13. Number of examples to use in each iteration: 1000\n",
      "\t\t14. The number of inner loops for the generator: 5\n",
      "\t\t15. The number of inner loops for the discriminator: 5\n",
      "\t\t16. Number of loops over training set: 5\n",
      "\t\t17. The l2 loss regulation weight for the generator: 1e-05\n",
      "\t\t18. The l2 loss regulation weight for the discriminator: 1e-05\n",
      "\t\t19. Learning rate: 0.001\n",
      "\t\t20. Sample new nodes for the discriminator for every disinterval iterations: 2\n",
      "\t\t21. Number of parallel workers: 2\n",
      "100%|████████████████████████████████████████| 19/19 [00:00<00:00, 2722.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Building Graph...\n",
      "\t>> Building BFS-trees...\n",
      "\t>> Building GAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>> Training GAN model...\n",
      "\t>> Extracting clusters...00.00%...\n",
      "\t>> Perform splitting (extreme)...\n",
      "\t\t--> Starting score: 66\n",
      "\t\t--> Splitting progress: 100.00%; score: 9.86\n"
     ]
    }
   ],
   "source": [
    "st = GANStratification(dimension_size=50, num_examples2gen=20, update_ratio=1, window_size=2,\n",
    "                       num_subsamples=10000, num_clusters=5, sigma=2, swap_probability=0.1,\n",
    "                       threshold_proportion=0.1, decay=0.1, shuffle=True, split_size=split_size,\n",
    "                       batch_size=1000, max_iter_gen=num_epochs, max_iter_dis=num_epochs, \n",
    "                       num_epochs=num_epochs, lambda_gen=1e-5, lambda_dis=1e-5, lr=1e-3, \n",
    "                       display_interval=2, num_jobs=num_jobs)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 351\n",
      "\t>> Number of labels: 654\n",
      "\t>> Label cardinality: 1.863248\n",
      "\t>> Label density: 0.002849\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.054131\n",
      "\t>> Number of tail labels of size 1: 0\n",
      "\t>> Number of dominant labels of size 2: 19\n",
      "## SELECTED (training set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 285\n",
      "\t>> Number of labels: 533\n",
      "\t>> Label cardinality: 1.870175\n",
      "\t>> Label density: 0.003509\n",
      "\t>> Distinct label sets: 19\n",
      "\t>> Proportion of distinct label sets: 0.066667\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.002121\n",
      "## SELECTED (test set) DATA PROPERTIES for birds...\n",
      "\t>> Number of examples: 66\n",
      "\t>> Number of labels: 121\n",
      "\t>> Label cardinality: 1.833333\n",
      "\t>> Label density: 0.015152\n",
      "\t>> Distinct label sets: 18\n",
      "\t>> Proportion of distinct label sets: 0.272727\n",
      "\t>> KL difference between two full and selected examples labels distributions: 0.043681\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gan2split\"\n",
    "data_properties(y=y.toarray(), selected_examples=training_idx, num_tails=1,\n",
    "                display_full_properties=True, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"training\",\n",
    "                rspath=RESULT_PATH)\n",
    "data_properties(y=y.toarray(), selected_examples=test_idx, num_tails=1,\n",
    "                display_full_properties=False, dataset_name=dsname,\n",
    "                model_name=model_name, split_set_name=\"test\",\n",
    "                rspath=RESULT_PATH, mode=\"a\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
