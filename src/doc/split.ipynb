{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# Stratified Splitting\n",
    "\n",
    "This notebook provides several tutorials on how to utilize any algorithm proposed\n",
    "in the **straSplit** package to split a multi-label dataset using less explored\n",
    "[stratified strategy](https://bit.ly/3s3IDA8). Please install\n",
    "[anaconda](https://www.anaconda.com/) package and other modules listed\n",
    "in [requirement.txt](../../requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive splitting strategy\n",
    "\n",
    "The naive based strategy does not address the class-imbalance problem and\n",
    "neither takes into account label-correlations to split a dataset. You can\n",
    "run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.naive2split import NaiveStratification\n",
    "\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    y = lil_matrix(y[y.getnnz(axis=1) != 0][:, y.getnnz(axis=0) != 0].A)\n",
    "\n",
    "st = NaiveStratification(shuffle=True, split_size=0.8, batch_size=1000, num_jobs=10)\n",
    "training_idx, test_idx = st.fit(y=y)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme splitting strategy\n",
    "\n",
    "CycleGAN uses a cycle consistency loss to enable training without the need for paired data. In other words, it can translate from one domain to another without a one-to-one mapping between the source and target domain.\n",
    "This opens up the possibility to do a lot of interesting tasks like photo-enhancement, image colorization, style transfer, etc. All you need is the source and the target dataset (which is simply a directory of images).\n",
    "\n",
    "As mentioned in the [paper](https://arxiv.org/abs/1703.10593), apply random jittering and mirroring to the training dataset. These are some of the image augmentation techniques that avoids overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuGVPOo7Cce0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.extreme2split import ExtremeStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "\n",
    "st = ExtremeStratification(swap_probability=0.1, threshold_proportion=0.1, decay=0.1,\n",
    "                            shuffle=True, split_size=0.75, num_epochs=50)\n",
    "training_idx, test_idx = st.fit(X=X, y=y)\n",
    "training_idx, dev_idx = st.fit(X=X[training_idx], y=y[training_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvX8sKsfMaio"
   },
   "source": [
    "## Community based splitting strategy\n",
    "\n",
    "Import the generator and the discriminator used in [Pix2Pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py) via the installed [tensorflow_examples](https://github.com/tensorflow/examples) package.\n",
    "\n",
    "The model architecture used in this tutorial is very similar to what was used in [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). Some of the differences are:\n",
    "\n",
    "* Cyclegan uses [instance normalization](https://arxiv.org/abs/1607.08022) instead of [batch normalization](https://arxiv.org/abs/1502.03167).\n",
    "* The [CycleGAN paper](https://arxiv.org/abs/1703.10593) uses a modified `resnet` based generator. This tutorial is using a modified `unet` generator for simplicity.\n",
    "\n",
    "There are 2 generators (G and F) and 2 discriminators (X and Y) being trained here. \n",
    "\n",
    "* Generator `G` learns to transform image `X` to image `Y`. $(G: X -> Y)$\n",
    "* Generator `F` learns to transform image `Y` to image `X`. $(F: Y -> X)$\n",
    "* Discriminator `D_X` learns to differentiate between image `X` and generated image `X` (`F(Y)`).\n",
    "* Discriminator `D_Y` learns to differentiate between image `Y` and generated image `Y` (`G(X)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ju9Wyw87MRW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.comm2split import CommunityStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "use_extreme = True\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "\n",
    "st = CommunityStratification(num_subsamples=10000, num_communities=5, walk_size=4, sigma=2,\n",
    "                                swap_probability=0.1, threshold_proportion=0.1, decay=0.1,\n",
    "                                shuffle=True, split_size=0.75, batch_size=100, num_epochs=50,\n",
    "                                num_jobs=2)\n",
    "training_idx, test_idx = st.fit(y=y, X=X, use_extreme=use_extreme)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx], X=X[training_idx], use_extreme=use_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based splitting strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.plssvd2split import ClusterStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "use_extreme = True\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "    \n",
    "st = ClusterStratification(num_clusters=5, swap_probability=0.1, threshold_proportion=0.1,\n",
    "                           decay=0.1, shuffle=True, split_size=0.75, batch_size=100,\n",
    "                           num_epochs=5, lr=0.0001, num_jobs=2)\n",
    "training_idx, test_idx = st.fit(y=y, X=X, use_extreme=use_extreme)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx], X=X[training_idx], use_extreme=use_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Clustering eigenvalues based splitting strategy\n",
    "\n",
    "In CycleGAN, there is no paired data to train on, hence there is no guarantee that the input `x` and the target `y` pair are meaningful during training. Thus in order to enforce that the network learns the correct mapping, the authors propose the cycle consistency loss.\n",
    "\n",
    "The discriminator loss and the generator loss are similar to the ones used in [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix#build_the_generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.eigencluster2split import ClusteringEigenStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "use_extreme = True\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "\n",
    "st = ClusteringEigenStratification(num_subsamples=10000, num_clusters=5, sigma=2, swap_probability=0.1,\n",
    "                                   threshold_proportion=0.1, decay=0.1, shuffle=True, split_size=0.75,\n",
    "                                   batch_size=100, num_epochs=50, num_jobs=2)\n",
    "training_idx, test_idx = st.fit(y=y, X=X, use_extreme=use_extreme)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx], X=X[training_idx], use_extreme=use_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Label Enhancement based splitting strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.enhance2split import LabelEnhancementStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "use_extreme = True\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "\n",
    "st = LabelEnhancementStratification(num_subsamples=10000, num_communities=5, walk_size=4, sigma=2, alpha=0.2,\n",
    "                                    swap_probability=0.1, threshold_proportion=0.1, decay=0.1, shuffle=True,\n",
    "                                    split_size=0.75, batch_size=100, num_epochs=50, num_jobs=2)\n",
    "training_idx, test_idx = st.fit(y=y, X=X, use_extreme=use_extreme)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx], X=X[training_idx], use_extreme=use_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Active learning based splitting strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.active2split import ActiveStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "\n",
    "st = ActiveStratification(subsample_labels_size=10, acquisition_type=\"psp\", top_k=5, swap_probability=0.1, \n",
    "                          threshold_proportion=0.1, decay=0.1, penalty='l21', alpha_elastic=0.0001, \n",
    "                          l1_ratio=0.65, alpha_l21=0.01, loss_threshold=0.05, shuffle=True,\n",
    "                          split_size=0.75, batch_size=100, num_epochs=50, lr=1e-3,\n",
    "                          display_interval=2, num_jobs=2)\n",
    "training_idx, test_idx = st.fit(y=y, X=X)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx], X=X[training_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## GAN learning based splitting strategy\n",
    "\n",
    "Note: This example model is trained for fewer epochs (40) than the paper (200) to keep training time reasonable for this tutorial. Predictions may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from scipy.sparse import lil_matrix\n",
    "from src.utility.file_path import DATASET_PATH\n",
    "from src.model.gan2split import GANStratification\n",
    "\n",
    "X_name = \"Xbirds_train.pkl\"\n",
    "y_name = \"Ybirds_train.pkl\"\n",
    "use_extreme = True\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, y_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    y = pkl.load(f_in)\n",
    "    idx = list(set(y.nonzero()[0]))\n",
    "    y = y[idx]\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, X_name)\n",
    "with open(file_path, mode=\"rb\") as f_in:\n",
    "    X = pkl.load(f_in)\n",
    "    X = X[idx]\n",
    "\n",
    "st = GANStratification(dimension_size=50, num_examples2gen=20, update_ratio=1, window_size=2,\n",
    "                       num_subsamples=10000, num_clusters=5, sigma=2, swap_probability=0.1,\n",
    "                       threshold_proportion=0.1, decay=0.1, shuffle=True, split_size=0.75,\n",
    "                       batch_size=100, max_iter_gen=30, max_iter_dis=30, num_epochs=5, lambda_gen=1e-5,\n",
    "                       lambda_dis=1e-5, lr=1e-3, display_interval=30, num_jobs=2)\n",
    "training_idx, test_idx = st.fit(y=y, X=X, use_extreme=use_extreme)\n",
    "training_idx, dev_idx = st.fit(y=y[training_idx], X=X[training_idx], use_extreme=use_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>> Training set size: {0}\".format(len(training_idx)))\n",
    "print(\"\\t>> Validation set size: {0}\".format(len(dev_idx)))\n",
    "print(\"\\t>> Test set size: {0}\".format(len(test_idx)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
